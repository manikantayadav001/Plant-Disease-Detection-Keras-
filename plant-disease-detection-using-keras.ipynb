{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"1020827e241ac87ffdf8e0f8762a6885bdc28fbc"},"source":["Import neccessary packages"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import pickle\n","import cv2\n","from os import listdir\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.models import Sequential\n","from keras.layers import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation, Flatten, Dropout, Dense\n","from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.preprocessing import image\n","from keras.utils import img_to_array\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":19,"metadata":{"_uuid":"7c3354a78e21a1a62ad0c4689d0ab3238fb760d4","trusted":true},"outputs":[],"source":["EPOCHS = 25\n","INIT_LR = 1e-3\n","BS = 32\n","default_image_size = tuple((256, 256))\n","image_size = 0\n","directory_root = './PlantVillage'\n","width=256\n","height=256\n","depth=3"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"2bf7ac0a0b805946f844a48e55d5281403e53f57"},"source":["Function to convert images to array"]},{"cell_type":"code","execution_count":20,"metadata":{"_uuid":"c9c3e60b13ace6c8f3e54336e12f9970fde438a3","trusted":true},"outputs":[],"source":["def convert_image_to_array(image_dir):\n","    try:\n","        image = cv2.imread(image_dir)\n","        if image is not None :\n","            image = cv2.resize(image, default_image_size)   \n","            return img_to_array(image)\n","        else :\n","            return np.array([])\n","    except Exception as e:\n","        print(f\"Error : {e}\")\n","        return None"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"24d42b87fad54a9556f78357ce673cc5152468c1"},"source":["Fetch images from directory"]},{"cell_type":"code","execution_count":26,"metadata":{"_uuid":"bb8d4c343314028f52ae3c3a840478a834a16c95","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Loading images ...\n","[INFO] Processing 0022d6b7-d47c-4ee2-ae9a-392a53f48647___JR_B.Spot 8964.JPG ...\n","Error : [WinError 267] The directory name is invalid: './PlantVillage/Pepper__bell___Bacterial_spot/0022d6b7-d47c-4ee2-ae9a-392a53f48647___JR_B.Spot 8964.JPG/'\n"]}],"source":["image_list, label_list = [], []\n","try:\n","    print(\"[INFO] Loading images ...\")\n","    root_dir = listdir(directory_root)\n","    for directory in root_dir :\n","        # remove .DS_Store from list\n","        if directory == \".DS_Store\" :\n","            root_dir.remove(directory)\n","\n","    for plant_folder in root_dir :\n","        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n","\n","        for disease_folder in plant_disease_folder_list :\n","            # remove .DS_Store from list\n","            if disease_folder == \".DS_Store\" :\n","                plant_disease_folder_list.remove(disease_folder)\n","\n","        for plant_disease_folder in plant_disease_folder_list:\n","            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n","            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n","                \n","            for single_plant_disease_image in plant_disease_image_list :\n","                if single_plant_disease_image == \".DS_Store\" :\n","                    plant_disease_image_list.remove(single_plant_disease_image)\n","\n","            for image in plant_disease_image_list[:200]:\n","                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n","                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n","                    image_list.append(convert_image_to_array(image_directory))\n","                    label_list.append(plant_disease_folder)\n","               \n","    print(\"[INFO] Image loading completed\")  \n","except Exception as e:\n","    print(f\"Error : {e}\")\n"," "]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"35c4b76d33e0263523e479657580104532f81d6e"},"source":["Get Size of Processed Image"]},{"cell_type":"code","execution_count":22,"metadata":{"_uuid":"6ee1ad9c422f112ec2862699b5c0f68b8d658123","trusted":true},"outputs":[],"source":["image_size = len(image_list)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"905b41b226f3fd82a88e67821eb42a07f24b31f7"},"source":["Transform Image Labels uisng [Scikit Learn](http://scikit-learn.org/)'s LabelBinarizer"]},{"cell_type":"code","execution_count":23,"metadata":{"_uuid":"904ff893fe14f5060dd9e7be2ccf96ec793597e5","trusted":true},"outputs":[{"ename":"ValueError","evalue":"y has 0 samples: []","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m label_binarizer \u001b[39m=\u001b[39m LabelBinarizer()\n\u001b[1;32m----> 2\u001b[0m image_labels \u001b[39m=\u001b[39m label_binarizer\u001b[39m.\u001b[39;49mfit_transform(label_list)\n\u001b[0;32m      3\u001b[0m pickle\u001b[39m.\u001b[39mdump(label_binarizer,\u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mlabel_transform.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m n_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(label_binarizer\u001b[39m.\u001b[39mclasses_)\n","File \u001b[1;32mc:\\Users\\nmani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n","File \u001b[1;32mc:\\Users\\nmani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:334\u001b[0m, in \u001b[0;36mLabelBinarizer.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m    315\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit label binarizer/transform multi-class labels to binary labels.\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \n\u001b[0;32m    317\u001b[0m \u001b[39m    The output of transform is sometimes referred to as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39m        will be of CSR format.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(y)\u001b[39m.\u001b[39mtransform(y)\n","File \u001b[1;32mc:\\Users\\nmani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:308\u001b[0m, in \u001b[0;36mLabelBinarizer.fit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMultioutput target data is not supported with label binarization\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m     )\n\u001b[0;32m    307\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my has 0 samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y)\n\u001b[0;32m    310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_input_ \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39missparse(y)\n\u001b[0;32m    311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m unique_labels(y)\n","\u001b[1;31mValueError\u001b[0m: y has 0 samples: []"]}],"source":["label_binarizer = LabelBinarizer()\n","image_labels = label_binarizer.fit_transform(label_list)\n","pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n","n_classes = len(label_binarizer.classes_)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"f860c29a1d714f06d25e6a0c5bca94739e5d24cc"},"source":["Print the classes"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0f876397c40c3c8aa09772a92fd60481fc9ba268","trusted":true},"outputs":[],"source":["print(label_binarizer.classes_)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6cd9c977b3d164a5570a0c24fdd8624adb9d56b8","trusted":true},"outputs":[],"source":["np_image_list = np.array(image_list, dtype=np.float16) / 225.0"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"9f4829560fdfa218cee18c1cfb2eb9452ef180e5","trusted":true},"outputs":[],"source":["print(\"[INFO] Spliting data to train, test\")\n","x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"eec8afa64e676d52c814fc8e096955a60f13b6c5","trusted":true},"outputs":[],"source":["aug = ImageDataGenerator(\n","    rotation_range=25, width_shift_range=0.1,\n","    height_shift_range=0.1, shear_range=0.2, \n","    zoom_range=0.2,horizontal_flip=True, \n","    fill_mode=\"nearest\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["model = Sequential()\n","inputShape = (height, width, depth)\n","chanDim = -1\n","if K.image_data_format() == \"channels_first\":\n","    inputShape = (depth, height, width)\n","    chanDim = 1\n","model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization(axis=chanDim))\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","model.add(Dropout(0.25))\n","model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization(axis=chanDim))\n","model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization(axis=chanDim))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Conv2D(128, (3, 3), padding=\"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization(axis=chanDim))\n","model.add(Conv2D(128, (3, 3), padding=\"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization(axis=chanDim))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(1024))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(Dense(n_classes))\n","model.add(Activation(\"softmax\"))"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"53b13c03e4cea6dc2453a84e254b806ebeed2d99"},"source":["Model Summary"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"1e1523a834fbf872940171fbdefb3dcce2b5f31b","trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b21dffee32c325136b4ea23ac511049723f34a24","trusted":true},"outputs":[],"source":["opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n","# distribution\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n","# train the network\n","print(\"[INFO] training network...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"1a13efc5ded339fc3c0d9e61041e8ca555362db0","trusted":true},"outputs":[],"source":["history = model.fit_generator(\n","    aug.flow(x_train, y_train, batch_size=BS),\n","    validation_data=(x_test, y_test),\n","    steps_per_epoch=len(x_train) // BS,\n","    epochs=EPOCHS, verbose=1\n","    )"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"1495fea08b37e4d4293f975ba30e6c1fc7a85ed9"},"source":["Plot the train and val curve"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0af5e0f23657a4effc2d21cf8e840e81f42ec8e7","trusted":true},"outputs":[],"source":["acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(acc) + 1)\n","#Train and validation accuracy\n","plt.plot(epochs, acc, 'b', label='Training accurarcy')\n","plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n","plt.title('Training and Validation accurarcy')\n","plt.legend()\n","\n","plt.figure()\n","#Train and validation loss\n","plt.plot(epochs, loss, 'b', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and Validation loss')\n","plt.legend()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"9ca1a4489bd624c69a13cd37c0c2306ac8de55c2"},"source":["Model Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"bb44f3d0b7e2862bc7d1a032612ebfd48212c1fe","trusted":true},"outputs":[],"source":["print(\"[INFO] Calculating model accuracy\")\n","scores = model.evaluate(x_test, y_test)\n","print(f\"Test Accuracy: {scores[1]*100}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"2a1f759db8afe933e62fe4cf8332cb303bb11be8"},"source":["Save model using Pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"5cdf06adf492d79ed28fbdc36e02ad7489c7b33e","trusted":true},"outputs":[],"source":["# save the model to disk\n","print(\"[INFO] Saving model...\")\n","pickle.dump(model,open('cnn_model.pkl', 'wb'))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":1}
